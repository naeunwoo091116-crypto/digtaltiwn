"""
ë‹¤ì¤‘ GPU í™˜ê²½ì—ì„œ ì—¬ëŸ¬ ì‹œìŠ¤í…œì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆ
"""
import multiprocessing as mp
from typing import List, Tuple, Callable, Any
import os


def run_system_on_gpu(gpu_id: int, element_pair: Tuple[str, str],
                      pipeline_func: Callable, *args) -> Any:
    """
    íŠ¹ì • GPUì—ì„œ í•˜ë‚˜ì˜ ì‹œìŠ¤í…œì„ ì‹¤í–‰

    :param gpu_id: ì‚¬ìš©í•  GPU ID (0, 1, 2, ...)
    :param element_pair: (element_A, element_B) íŠœí”Œ
    :param pipeline_func: ì‹¤í–‰í•  íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜
    :param args: ì¶”ê°€ ì¸ìë“¤
    :return: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼
    """
    # GPU í• ë‹¹ (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)

    print(f"ğŸš€ GPU {gpu_id}: {element_pair[0]}-{element_pair[1]} ì‹œìŠ¤í…œ ì‹œì‘")

    try:
        result = pipeline_func(element_pair[0], element_pair[1], *args)
        return result
    except Exception as e:
        print(f"âŒ GPU {gpu_id} ì˜¤ë¥˜: {e}")
        return None


class ParallelSystemRunner:
    """
    ì—¬ëŸ¬ ì›ì†Œ ì¡°í•©ì„ ë‹¤ì¤‘ GPUì—ì„œ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ëŠ” í´ë˜ìŠ¤
    """
    def __init__(self, num_gpus: int = 1):
        """
        :param num_gpus: ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜
        """
        self.num_gpus = num_gpus

    def run_parallel(self, element_pairs: List[Tuple[str, str]],
                     pipeline_func: Callable, *args) -> List[Any]:
        """
        ì—¬ëŸ¬ ì‹œìŠ¤í…œì„ ë³‘ë ¬ë¡œ ì‹¤í–‰

        :param element_pairs: [(elem_A, elem_B), ...] ë¦¬ìŠ¤íŠ¸
        :param pipeline_func: ê° ì‹œìŠ¤í…œì— ëŒ€í•´ ì‹¤í–‰í•  í•¨ìˆ˜
        :param args: ì¶”ê°€ ì¸ìë“¤
        :return: ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if self.num_gpus <= 1:
            # ë‹¨ì¼ GPU: ìˆœì°¨ ì‹¤í–‰
            print("â„¹ï¸  ë‹¨ì¼ GPU ëª¨ë“œ: ìˆœì°¨ ì‹¤í–‰")
            results = []
            for elem_A, elem_B in element_pairs:
                result = pipeline_func(elem_A, elem_B, *args)
                results.append(result)
            return results

        # ë‹¤ì¤‘ GPU: ë³‘ë ¬ ì‹¤í–‰
        print(f"ğŸš€ ë‹¤ì¤‘ GPU ëª¨ë“œ: {self.num_gpus}ê°œ GPU ì‚¬ìš©")

        # í”„ë¡œì„¸ìŠ¤ í’€ ìƒì„±
        with mp.Pool(processes=self.num_gpus) as pool:
            # GPUë¥¼ ìˆœí™˜í•˜ë©´ì„œ í• ë‹¹
            tasks = []
            for idx, (elem_A, elem_B) in enumerate(element_pairs):
                gpu_id = idx % self.num_gpus
                task = pool.apply_async(
                    run_system_on_gpu,
                    args=(gpu_id, (elem_A, elem_B), pipeline_func, *args)
                )
                tasks.append(task)

            # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
            results = [task.get() for task in tasks]

        return results
